<!DOCTYPE html>
<html lang="en">

<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css">
    <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.3/dist/jquery.slim.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.3.0/css/all.min.css">
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.2.3/dist/js/bootstrap.bundle.min.js"></script>
    <script src="https://cdn.zingchart.com/zingchart.min.js"></script>
    <title>Tamoghnas's Diffusion MRI Paper</title>
    <link href="blog.css" rel="stylesheet" type="text/css" />

    <!-- load the d3.js library -->
    <!-- <script src="https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.17/d3.min.js"></script> -->

    <!-- blinking arrow -->
    <!-- <div class="arrow-container">
        <div class="arrow"></div>
    </div> -->



</head>

<body>
    <nav class="navbar navbar-expand-md header" style="background-color: black;">
        <a class="navbar-brand" href="#" style="color: #b8860b; font-size: 28px; font-weight: bold;">IGC</a>

        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarNav"
            aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="navbar navbar-title">
            <h1>Fusion Model for PD</h1>
        </div>

        <div class="collapse navbar-collapse" id="navbarNav">
            <ul class="navbar-nav ml-auto">
                <li class="nav-item active">
                    <a class="nav-link" style="color: whitesmoke;" href="index.html">Home</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link" style="color: whitesmoke;" href="../AI@IGC.html">AI @ IGC</a>
                </li>
                <li class="nav-item">
                    <a class="nav-link hover-link" href="./index.html">Blog</a>
                </li>
            </ul>
        </div>

    </nav>

    <div id="layout">
        <div id="sidebar">
            <h3>Jump to</h3>
            <div id="custom-toc-container">
                <div class="toc">
                    <ul>
                        <li>
                        <li><a href="#diffusion_title">Fusion Model for PD</a>
                            <ul>
                                <li><a href="#introduction">Introduction</a></li>
                                <li><a href="#model">Model</a></li>
                                <li><a href="#results">Results</a></li>
                            </ul>



                </div>

            </div>
        </div>
        <div id="content-container">
            <div class="markdown-body markdown-content">
                <!-- <div class="container text-center" id="vit"> -->
                <h2 style="color : #D4AC0D" id="diffusion_title"><b>Fusing anatomical and diffusion MRIs for detecting
                        Parkinsonâ€™s disease</b></h2>
                <!-- <p class="container pt-3 pr-5 pl-5 text-justify" style="color : white"> One of the most common deep
                        learning
                        layers for processing brain MRI inputs are the 3D convolutional layers. 3D convolutional neural
                        networks
                        - also known as roCNNs, or ConvNets - are an extension of 2D CNNs where the kernels are 3D. They
                        were
                        developed in order to take advantage of the spatial information present in 3D medical images.
                        However,
                        3D convolutional neural networks require more parameters and can only work with are specific to 3D
                        images. This specificity restricts the use or adapt of any typically neural network trained on more
                        common 2D images (or natural images, such as photographs), or to adapt such a network to
                        neuroimaging
                        tasks. To this end, we introduced 2D-Slice CNN models that process one 2D slice at a time with
                        traditional 2D convolutional networks and combine the resulting representations using recurrent
                        operations and set operations. These models achieve performance similar to 3D-CNNs while being
                        faster to
                        train, more data-efficient, and less susceptible to noise in MRI slices. We further showed in a
                        paper at
                        ISBI 2023 that these 2D encoder-based models improve performance when initialized with
                        state-of-the-art
                        standard computer vision models.</p> -->

                <h3 id="introduction">Introduction</h3>
                <p>Deep learning models based on convolutional neural networks (CNNs) effectively extract meaningful
                    features from raw MRI scans. However, these models have predominantly been tested using T1-weighted
                    brain MRI data. This study investigates the added value of diffusion-weighted MRI (dMRI), which
                    captures microstructural tissue properties, as an additional input for CNN-based models; we
                    illustrate their use there for a Parkinson's Disease (PD) classification task.
                </p>
                </ul>
                <img class="container pt-3 pr-5 pl-5" src="../blogimages/fusion_gif.gif">
                <h3 id="model">Model</h3>
                <p>We propose a Y-shaped architecture for dual-modality training that uses separate 3D CNNs to distill
                    predictive features from the anatomical MRI and diffusion MRIs. These are then merged/concatenated
                    for PD classification.
                </p>

                <h3 id="results">Results</h3>
                <p>Our evaluation involves data from three cohorts: Chang Gung University, the University of
                    Pennsylvania (UPenn), and the Parkinson's Progression Markers Initiative (PPMI). In our
                    dual-modality experiments, we found that combining T1-weighted images (T1w) with diffusion-weighted
                    imaging mean diffusivity (DWI-MD) and axial diffusivity (DWI-AD) yielded some promising results
                    compared to the other combinations tested. In most cases, using a combination of T1w and dMRI
                    improved the balanced accuracy compared to using T1w alone. However, these models should benefit
                    from more training data, considering the large dimension of the input data and the limited amount of
                    training samples available. Surprisingly, despite the expectation that the fused model, which
                    incorporates more information, would outperform the models using only DWIs, we found that the fused
                    model's balanced accuracy was still lower than the case where DWIs were the sole input. We may
                    require a larger dataset to leverage the fused model's advantages effectively.
                </p> <br>
                <p>We also discovered an intriguing finding regarding classifying the Parkinson's Progression Markers
                    Initiative (PPMI) dataset. PPMI proved more challenging to classify than the other two datasets we
                    examined. One possible explanation for this discrepancy is the mean Hoehn and Yahr (H&Y) stage
                    distribution among the patients in each dataset. Specifically, the average H&Y stage follows the
                    order: UPenn (2.64) > Taiwan (2.24) > PPMI (1.59), indicating that patients in the PPMI dataset may
                    generally exhibit milder brain abnormalities compared to those in the other datasets.
                </p> <br>
                <p>These findings underscore the potential of combining T1-weighted and diffusion-weighted imaging
                    modalities for improved accuracy in Parkinson's disease classification. However, further research
                    with larger datasets is necessary to fully harness the benefits of these combined models and enhance
                    our understanding of the unique characteristics of different datasets.
                </p>





            </div>
        </div>
    </div>
    <div id="all_posts">
        <h3> All Posts</h3>
        <div id="all-posts-container">
            <ul class='posts'>
                <li><a href='introducing.html'>Introducing AI for Neuroimaging @ IGC</a>
                <li><a href='dMRI_dementia.html'>Tamoghnas's Diffusion MRI Paper</a>
                <li><a href='sipaim_2022_nikhil_transfer.html'>Nikhil's SIPAIM 2022 Transfer Learning Paper</a>
                <li><a href='table+t1mri_amyloid.html'>Features + T1 MRI for amyloid prediction</a>
                <li><a href='harmonizing_with_cycle_gan.html'>Dheeraj's Harmonization Paper</a>
                <li><a href='vit_AD.html'>Vision Transformers</a>
            </ul>
        </div>
    </div>
    </div>
</body>

<script>

</script>

<script type="text/javascript" src="active-view.js"></script>

</html>